{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.vis_utils import plot_model \n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import sklearn\n",
    "import datetime\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import itertools\n",
    "from tensorflow.keras.applications import VGG19, ResNet50V2, MobileNet, DenseNet121, InceptionV3\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = layers.Input(shape=(224, 224, 3))\n",
    "dataset_name = 'Dataset1'\n",
    "pre_traind_base = DenseNet121(include_top = False, \n",
    "                                weights='imagenet', input_tensor=inp,\n",
    "                                input_shape=[224,224, 3])\n",
    "pre_traind_base.trainable = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"1\",\"2\",\"3\",\"4\"]\n",
    "num_classes = len(categories)\n",
    "img_rows, img_cols = 224, 224\n",
    "X_train, X_test, Y_train, Y_test = np.load(f'D:/article/npy/{dataset_name}.npy', allow_pickle = True)\n",
    "epoch = 20\n",
    "savename = f\"D:/article/result/Mobile_{dataset_name}_{epoch}/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(16, (3, 3), strides=(1,1), input_shape=(224,224, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides = (2,2)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides = (2,2)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides = (2,2)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides = (2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation = 'softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trainsfer_classifier():\n",
    "    flat1 = layers.Flatten()(pre_traind_base.layers[-1].output)\n",
    "    x = layers.Dense(128, activation='relu')(flat1)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model =  Model(inputs=pre_traind_base.inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_trainsfer_classifier()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'] )\n",
    "start_time = datetime.datetime.now()\n",
    "history = model.fit(X_train, Y_train, epochs=epoch, validation_split=0.2 )\n",
    "end_time = datetime.datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"training time: {elapsed_time} sec\")\n",
    "_, acc = model.evaluate(X_test, Y_test)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time2 = datetime.datetime.now()\n",
    "y_pred = model.predict(X_test) \n",
    "end_time2 = datetime.datetime.now()\n",
    "elapsed_time2 = end_time2 - start_time2\n",
    "print(f\"test time: {elapsed_time2} sec\")\n",
    "print(f\"training time: {elapsed_time} sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_pred = y_pred\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(Y_test, axis=1)\n",
    "matric = sklearn.metrics.confusion_matrix(y_test, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "weight = pd.DataFrame(weight_pred)\n",
    "weight['y_pred'] = y_pred\n",
    "weight['y_true'] = y_test\n",
    "hist = pd.DataFrame(history.history)\n",
    "matric = pd.DataFrame(matric)\n",
    "weight = pd.DataFrame(weight)\n",
    "\n",
    "\n",
    "model.save(f\"{savename}model.h5\")\n",
    "hist.to_excel(f\"{savename}history.xlsx\")\n",
    "matric.to_excel(f\"{savename}matric.xlsx\")\n",
    "weight.to_excel(f\"{savename}weight.xlsx\")\n",
    "with open(f\"{savename}time.txt\", \"w\") as f:\n",
    "    f.write(f\"training: {elapsed_time}\\ntest: {elapsed_time2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matric = sklearn.metrics.confusion_matrix(y_test, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "plt.imshow(matric, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(num_classes)\n",
    "# plt.xticks(tick_marks, ['high grade','third', 'out of'])\n",
    "# plt.yticks(tick_marks, ['high grade','third', 'out of'])\n",
    "plt.xticks(tick_marks, ['first', 'second','third', 'out of'])\n",
    "plt.yticks(tick_marks, ['first', 'second','third', 'out of'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "thresh = matric.max() / 2.\n",
    "for i, j in itertools.product(range(matric.shape[0]), range(matric.shape[1])):\n",
    "    plt.text(j, i, format(matric[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if matric[i, j] > thresh else \"black\")\n",
    "plt.savefig(f\"{savename}matric.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Accuracy: {:.4f}'.format(accuracy))\n",
    "print('Precision: {:.4f}'.format(precision))\n",
    "print('Recall: {:.4f}'.format(recall))\n",
    "print('F1 score: {:.4f}'.format(f1))\n",
    "with open(f\"{savename}performance.txt\", \"w\") as f:\n",
    "    f.write(f\"Accuracy: {round(accuracy, 4)}\\nPrecision: {round(precision, 4)}\\nRecall: {round(recall, 4)}\\nF1_score: {round(f1, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "y_pred_cat = to_categorical(y_pred, num_classes=num_classes)\n",
    "# Calculate ROC AUC score\n",
    "auc = roc_auc_score(y_test_cat, y_pred_cat, multi_class='ovo')\n",
    "\n",
    "# Calculate FPR and TPR values for ROC curve\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_cat[:, i], y_pred_cat[:, i])\n",
    "    roc_auc[i] = roc_auc_score(y_test_cat[:, i], y_pred_cat[:, i])\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue', 'red']\n",
    "# colors = ['violet', 'cornflowerblue', 'red']\n",
    "for i, color in zip(range(num_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of {0} grade (AUC = {1:0.4f})'.format(['first', 'second', 'third', 'out of'][i], roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f\"{savename}AUC.jpg\")\n",
    "print('AUC: {:.4f}'.format(auc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
